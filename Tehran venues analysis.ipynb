{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Final capstone project", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Tehran venues analysis", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 1. Introduction\n\n### 1.1 Background\n\nTehran is a very big city in terms of the number of districts and population. Tehran has over 22 districts with a population of 12 million people(2018) which makes it the second most populated city in the middle east after Istanbul. A big city like Tehran has lot\u2019s of neighborhoods and many venues.\n\n### 1.2 Problem\n\nUnfortunately, a big city like Tehran doesn\u2019t have a good analysis of their venues. For example, a tourist doesn\u2019t know the best places in Tehran based on each neighborhood so In this project we are going to cluster each neighborhood in 22 districts of Tehran based on their top 10 venues in each neighborhood\n\n### 1.3 Interest\n\nThe output of this project can be very helpful for tourists or anyone who is interested in finding the best venues of Tehran based on their neigborhoods.\n\n## 2. Data acquisition\n\nSurprisingly, Tehran doesn\u2019t have a clean database for data scientists. As a data scientist you have to pretty much collect everything you need yourself. So my first step would be to collect neighborhoods data from here and put each one in a row of my Dataframe. After this step I will collect the coordinates for my neighborhoods to plot my data on a map. Coordinates will be collected by Geopy library. For the Final step, I will get my venues data based on each neighborhood using Foursquare API which surprisingly has a valuable database for the city of Tehran.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 3.Data analysis explanation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "For start first we first import our package:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting folium\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/ff/004bfe344150a064e558cb2aedeaa02ecbf75e60e148a55a9198f0c41765/folium-0.10.0-py2.py3-none-any.whl (91kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 13.9MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: jinja2>=2.9 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (2.10)\nCollecting branca>=0.3.0 (from folium)\n  Downloading https://files.pythonhosted.org/packages/63/36/1c93318e9653f4e414a2e0c3b98fc898b4970e939afeedeee6075dd3b703/branca-0.3.1-py3-none-any.whl\nRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (1.15.4)\nRequirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (2.21.0)\nRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from jinja2>=2.9->folium) (1.1.0)\nRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from branca>=0.3.0->folium) (1.12.0)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (2.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (3.0.4)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (1.24.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (2019.6.16)\nInstalling collected packages: branca, folium\nSuccessfully installed branca-0.3.1 folium-0.10.0\nLibraries imported.\n"
                }
            ], 
            "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport matplotlib.pyplot as plt\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n!pip install folium\nimport folium\n\nprint('Libraries imported.')"
        }, 
        {
            "source": "### 3.1 Data gathering\n\nNow we need to start our data gathering process. As explained above, since there is no csv file to convert data frame and wrangle the data we will create our dataframe directly using pandas library. The dataframe we are looking to create consists of columns <i> District, neighborhood, lantitude, logtitude </i>. To have the first two columns which are <b>District</b> and <b>neighborhood</b> we will get what we need from <a href=\"https://en.wikipedia.org/wiki/Template:Main_neighborhoods_of_Tehran\">here</a> and we will put each neighborhood to it's district. Since the data in this page is in Farsi and there is no table, data scraping tools can't help us to retrieve data from this page.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "data = None"
        }, 
        {
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "dg = [\n    ('North', 'Aghdasieh'),\n    ('North', 'Lavizan'),\n    ('North', 'Ajodanieh'),\n    ('North', 'Darakeh'),\n    ('North', 'Darband'),\n    ('North', 'Darrous'),\n    ('North', 'Davoodiyeh'),\n    ('North', 'Doulat'),\n    ('North', 'Ekhtiarieh'),\n    ('North', 'Elahieh'),\n    ('North', 'Farmanieh'),\n    ('North', 'Gheytarieh'),\n    ('North', 'Gholhak'),\n    ('North', 'Jamaran'),\n    ('North', 'Jordan'),\n    ('North', 'Kamranieh'),\n    ('North', 'Mahmoodieh'),\n    ('North', 'Mehran'),\n    ('North', 'Niavaran'),\n    ('North', 'Pasdaran'),\n    ('North', 'Shemiran'),\n    ('North', 'Tajrish'),\n    ('North', 'Vanak'),\n    ('North', 'Valiasr'),\n    ('North', 'Velenjak'),\n    ('North', 'Zafaraniyeh'),\n    ('West', 'Ekbatan'),\n    ('West', 'Apadana Complex'),\n    ('West', 'Baghe Feiz'),\n    ('West', 'Farahzad'),\n    ('West', 'Gisha'),\n    ('West', 'Jannat Abad'),\n    ('West', 'Punak'),\n    ('West', \"Sa'adat Abad\"),\n    ('West', 'Sadeghiyeh'),\n    ('West', 'Shahrak-e Gharb'),\n    ('West', 'Shahran'),\n    ('West', 'Shahrara'),\n    ('West', 'Shahr-e Ziba'),\n    ('West', 'Tarasht'),\n    ('West', 'Tehransar'),\n    ('Central', 'Abbas Abad'),\n    ('Central', 'Amir Abad'),\n    ('Central', 'Baharestan'),\n    ('Central', 'Enghelab Street'),\n    ('Central', 'Bazar'),\n    ('Central', 'Hasan Abad'),\n    ('Central', 'Jomhuri'),\n    ('Central', 'Keshavarz Boulvard'),\n    ('Central', 'Park-e Shahr'),\n    ('Central', 'Seyed Khandan'),\n    ('Central', 'Toopkhaneh'),\n    ('Central', 'Yusef Abad'),\n    ('East', 'Afsariyeh'),\n    ('East', 'Lavizan'),\n    ('East', 'Narmak'),\n    ('East', 'Tehranpars'),\n    ('East', 'Tehranno'),\n    ('East', 'Piroozi'),\n    ('South', 'Gomrok'),\n    ('South', 'Javadiyeh'),\n    ('South', 'Khavaran'),\n    ('South', 'Navvab'),\n    ('South', 'Nazi Abad'),\n    ('South', 'Rey'),\n    ('South', 'Yaft Abad')\n]\ndata = pd.DataFrame(dg, columns={'City side', 'Neighborhood'})"
        }, 
        {
            "execution_count": 27, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Tehran has 65 unique neighborhoods.\n"
                }
            ], 
            "source": "data.head()\nprint('Tehran has {} unique neighborhoods.'.format(len(data['Neighborhood'].unique())))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}